```
LLM/
β”β”€β”€ data/                                   # ν•™μµ/κ²€μ¦μ© JSONL λ°μ΄ν„° μ €μ¥ ν΄λ”
β”‚   β”β”€β”€ ReadMe.md                           # λ°μ΄ν„° μ„¤λ… λ¬Έμ„
β”‚   β”β”€β”€ train_merged.jsonl                  # μ‹¤μ  ν•™μµμ— μ‚¬μ©λλ” ν†µν•© ν•™μµ λ°μ΄ν„°
β”‚   β”β”€β”€ train.jsonl                         # κ°λ³„ ν•™μµ λ°μ΄ν„° (μ„μ‹ μ›λ³Έ)
β”‚   β””β”€β”€ valid.jsonl                         # κ²€μ¦μ©(optional) λ°μ΄ν„°
β”‚
β”β”€β”€ llama.cpp/                              # LoRA β†’ GGUF λ³€ν™μ© llama.cpp μ†μ¤
β”‚   β”β”€β”€ convert_lora_to_gguf.py             # HF LoRAλ¥Ό GGUF LoRAλ΅ λ³€ν™ν•λ” μ¤ν¬λ¦½νΈ
β”‚   β””β”€β”€ ...                                  # (llama.cppμ κΈ°νƒ€ νμΌλ“¤)
β”‚
β”β”€β”€ logs/                                   # ν•™μµ λ΅κ·Έ λ° κ²°κ³Όλ¬Ό μ €μ¥
β”‚
β”β”€β”€ models/                                 # (μµμ…) μ™„μ „ν• λ¨λΈ/LoRA λλ” merge κ²°κ³Ό μ €μ¥
β”‚
β”β”€β”€ outputs/                                # νμΈνλ‹ κ²°κ³Όλ¬Ό(LoRA μ–΄λ‘ν„°) μ €μ¥ ν΄λ”
β”‚   β””β”€β”€ lora-llama31-8b/                    # ν•™μµλ LoRA λ””λ ‰ν† λ¦¬
β”‚       β”β”€β”€ adapter_config.json             # LoRA κµ¬μ„± νμΌ
β”‚       β”β”€β”€ adapter_model.safetensors       # ν•™μµλ LoRA κ°€μ¤‘μΉ
β”‚       β””β”€β”€ tokenizer.*                     # ν† ν¬λ‚μ΄μ € λ©”νƒ€λ°μ΄ν„°(ν•„μ” μ‹)
β”‚
β”β”€β”€ scripts/                                # ν•™μµ/μ¶”λ΅ /λ°μ΄ν„° μƒμ„± μ¤ν¬λ¦½νΈ λ¨μ
β”‚   β”β”€β”€ finetune_qlora.py                   # QLoRA νμΈνλ‹ μ „μ²΄ νμ΄ν”„λΌμΈ
β”‚   β”β”€β”€ make_data.py                        # ν•™μµ λ°μ΄ν„° μƒμ„± μ¤ν¬λ¦½νΈ (μ: 100κ° Q&A μλ™μƒμ„±)
β”‚   β”β”€β”€ run_inference.py                    # ν•™μµλ LoRAλ΅ μ¶”λ΅  ν…μ¤νΈν•λ” μ¤ν¬λ¦½νΈ
β”‚   β””β”€β”€ ...                                  # κΈ°νƒ€ μ ν‹Έ μ¤ν¬λ¦½νΈ
β”‚
β”β”€β”€ venv/                                   # Python κ°€μƒν™κ²½(λ΅μ»¬ κ°λ°μ©)
β”‚
β”β”€β”€ .gitignore                              # Git μ—…λ΅λ“ μ μ™Έ μ„¤μ •
β”‚
β””β”€β”€ requirements.txt                         # pip freezeλ΅ μƒμ„±λ μμ΅΄μ„± λ©λ΅
```
π“ κ° ν΄λ”/νμΌμ κΈ°λ¥ μ”μ•½
π“ data/

ν•™μµ(train), κ²€μ¦(valid)μ© JSONLμ„ λ„£λ” ν΄λ”

LLM νμΈνλ‹μ—μ„ κΈ°λ³Έμ μΌλ΅ μ‚¬μ©λλ” λ°μ΄ν„° μ €μ¥ μ„μΉ

train_merged.jsonlμ΄ μµμΆ…μ μΌλ΅ λ¨λΈ ν•™μµμ— λ“¤μ–΄κ°€λ” νμΌ

π“ llama.cpp/

LoRA β†’ GGUF λ³€ν™μ„ μ„ν• llama.cpp μ†μ¤ μ €μ¥

convert_lora_to_gguf.pyλ¥Ό μ‚¬μ©ν•μ—¬
HuggingFace LoRA β†’ Ollamaμ© GGUF LoRA λ³€ν™ μν–‰

π“ logs/

ν•™μµν•λ©΄μ„ Trainerκ°€ μ°λ” λ΅κ·Έ νμΌμ„ λ³΄κ΄€

π“ models/

(ν•„μ” μ‹) μ™„μ „ν• λ³‘ν•© λ¨λΈ μ €μ¥ν•λ” μ©λ„

LoRA + λ² μ΄μ¤ λ¨λΈ merge κ²°κ³Όλ¥Ό λ„£μ„ λ• μ‚¬μ© κ°€λ¥

π“ outputs/

νμΈνλ‹ ν›„ LoRA μ–΄λ‘ν„° κ°€μ¤‘μΉκ°€ μ €μ¥λλ” ν•µμ‹¬ ν΄λ”

μ—¬κΈ° μλ” adapter_model.safetensorsκ°€ GGUF λ³€ν™μ μ…λ ¥μΌλ΅ μ‚¬μ©λ¨

π“ scripts/

ν”„λ΅μ νΈμ μ‹¤ν–‰ λ΅μ§μ΄ λ¨λ‘ λ“¤μ–΄μλ” ν•µμ‹¬ λ””λ ‰ν† λ¦¬

finetune_qlora.py β†’ ν•™μµ μ½”λ“

run_inference.py β†’ μ¶”λ΅  ν…μ¤νΈ μ½”λ“

make_data.py β†’ ν•™μµ λ°μ΄ν„° μλ™ μƒμ„±

π“ venv/

Python κ°€μƒν™κ²½

requirements.txtλ΅ μ–Έμ λ“ μ§€ μ¬μƒμ„± κ°€λ¥

requirements.txt

pip freezeλ΅ λ½‘μ€ κ°λ° ν™κ²½ λ³µμ› νμΌ

μƒ PCμ—μ„ λ™μΌν• ν™κ²½ κµ¬μ„± κ°€λ¥